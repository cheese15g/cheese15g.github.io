<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <title>Guitar Note Trainer</title>
  <style>
    body {
      margin: 0;
      padding: 20px;
      font-family: sans-serif;
      text-align: center;
      transition: background-color 0.3s;
    }
    #target {
      font-size: 2em;
      margin: 20px 0;
    }
  </style>
</head>
<body>
  <h1>기타 지판 암기 훈련</h1>
  <p id="target">목표 음: </p>
  <p>(마이크 허용 필요)</p>

  <script>
    // 간단한 음계 매핑 (기타 음계는 필요시 확장 가능)
    const notes = [
      { name: "E2", freq: 82.41 },
      { name: "A2", freq: 110.00 },
      { name: "D3", freq: 146.83 },
      { name: "G3", freq: 196.00 },
      { name: "B3", freq: 246.94 },
      { name: "E4", freq: 329.63 }
    ];

    // 목표 음 무작위 선택
    const targetNote = notes[Math.floor(Math.random() * notes.length)];
    document.getElementById("target").textContent = "목표 음: " + targetNote.name;

    // 오디오 분석 준비
    navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
      const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioCtx.createMediaStreamSource(stream);
      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      const buffer = new Float32Array(analyser.fftSize);

      source.connect(analyser);

      function autoCorrelate(buf, sampleRate) {
        // 오토코릴레이션 기반 피치 탐지 (간단 구현)
        let SIZE = buf.length;
        let MAX_SAMPLES = Math.floor(SIZE/2);
        let bestOffset = -1;
        let bestCorrelation = 0;
        let rms = 0;
        for (let i=0;i<SIZE;i++) {
          let val = buf[i];
          rms += val*val;
        }
        rms = Math.sqrt(rms/SIZE);
        if (rms<0.01) return -1; // 입력 너무 작음

        let lastCorrelation=1;
        for (let offset = 0; offset < MAX_SAMPLES; offset++) {
          let correlation = 0;
          for (let i=0; i<MAX_SAMPLES; i++) {
            correlation += Math.abs((buf[i])-(buf[i+offset]));
          }
          correlation = 1 - (correlation/MAX_SAMPLES);
          if (correlation > 0.9 && correlation > lastCorrelation) {
            bestCorrelation = correlation;
            bestOffset = offset;
          }
          lastCorrelation = correlation;
        }
        if (bestOffset > -1) {
          return sampleRate/bestOffset;
        }
        return -1;
      }

      function update() {
        analyser.getFloatTimeDomainData(buffer);
        let pitch = autoCorrelate(buffer, audioCtx.sampleRate);
        if (pitch !== -1) {
          let diff = Math.abs(pitch - targetNote.freq);
          if (diff < 5) {
            document.body.style.backgroundColor = "lightgreen"; // 정답
          } else {
            document.body.style.backgroundColor = "lightcoral"; // 오답
          }
        } else {
          document.body.style.backgroundColor = "white"; // 입력 없음
        }
        requestAnimationFrame(update);
      }
      update();
    }).catch(err => {
      alert("마이크 접근 불가: " + err);
    });
  </script>
</body>
</html>
